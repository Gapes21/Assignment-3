{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7857718,"sourceType":"datasetVersion","datasetId":4595676}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install deep-sort-realtime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T07:57:22.180702Z","iopub.execute_input":"2024-03-16T07:57:22.181125Z","iopub.status.idle":"2024-03-16T07:57:36.299963Z","shell.execute_reply.started":"2024-03-16T07:57:22.181093Z","shell.execute_reply":"2024-03-16T07:57:36.298939Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting deep-sort-realtime\n  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deep-sort-realtime) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from deep-sort-realtime) (1.11.4)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from deep-sort-realtime) (4.9.0.80)\nDownloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: deep-sort-realtime\nSuccessfully installed deep-sort-realtime-1.3.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport torch\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.transforms import functional as F\nfrom deep_sort_realtime.deepsort_tracker import DeepSort\nimport os\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:57:37.964133Z","iopub.execute_input":"2024-03-16T07:57:37.964881Z","iopub.status.idle":"2024-03-16T07:57:38.241317Z","shell.execute_reply.started":"2024-03-16T07:57:37.964846Z","shell.execute_reply":"2024-03-16T07:57:38.240426Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Detector and Tracker classes for a uniform interface\nclass Detector:\n    def __init__(self):\n        pass\n    def getDetections(self, frame):\n        pass\n\nclass Tracker:\n    def __init__(self):\n        pass\n    def getTrackedObjects(self, detections, frame):\n        pass","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:57:39.835477Z","iopub.execute_input":"2024-03-16T07:57:39.836151Z","iopub.status.idle":"2024-03-16T07:57:39.842885Z","shell.execute_reply.started":"2024-03-16T07:57:39.836121Z","shell.execute_reply":"2024-03-16T07:57:39.841871Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Detectors : \nclass DetectorFasterRCNN(Detector):\n    def __init__(self):\n        self.model = fasterrcnn_resnet50_fpn(pretrained = True)\n        self.model.eval()\n        self.model.to(device)\n        self.vehicle_classes = [2, 3, 4, 6]\n        \n    def getDetections(self, frame):\n        frame_tensor = F.to_tensor(frame).unsqueeze(0).to(device)\n        with torch.no_grad():\n            outputs = self.model(frame_tensor)\n        boxes = outputs[0]['boxes'].cpu().numpy()\n        scores = outputs[0]['scores'].cpu().numpy()\n        labels = outputs[0]['labels'].cpu().numpy()\n        detections = [(box, score, label) for box, score, label in zip(boxes, scores, labels) if score > 0.8 and label in self.vehicle_classes]\n        return detections\n\nclass DetectorYOLO(Detector):\n    def __init__(self):\n        self.model = None\n    \n    def getDetections(self, frame):\n        return []\n    \ndetectorFasterRCNN = DetectorFasterRCNN()\ndetectorYOLO = DetectorYOLO()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:57:41.857071Z","iopub.execute_input":"2024-03-16T07:57:41.857394Z","iopub.status.idle":"2024-03-16T07:57:44.234063Z","shell.execute_reply.started":"2024-03-16T07:57:41.857370Z","shell.execute_reply":"2024-03-16T07:57:44.233270Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n100%|██████████| 160M/160M [00:01<00:00, 155MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Trackers\nclass TrackerSORT(Tracker):\n    def __init__(self):\n        self.tracker = None\n    \n    def getTrackedObjects(self, detections, frame):\n        return self.tracker(detections, frame)\n    \nclass TrackerDeepSORT(Tracker):\n    def __init__(self):\n        self.tracker = DeepSort()\n    \n    def getTrackedObjects(self, detections, frame):\n        return self.tracker.update_tracks(detections, frame = frame)\n    \ntrackerSORT = TrackerSORT()\ntrackerDeepSORT = TrackerDeepSORT()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:57:55.045471Z","iopub.execute_input":"2024-03-16T07:57:55.045848Z","iopub.status.idle":"2024-03-16T07:57:55.181771Z","shell.execute_reply.started":"2024-03-16T07:57:55.045818Z","shell.execute_reply":"2024-03-16T07:57:55.180597Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class VehicleTracker:\n    def __init__(self, detector, tracker):\n        self.detector = detector\n        self.tracker = tracker\n        \n    def writeVideo(self, frames, output_file='output.mp4', fps=30):\n        height, width, _ = frames[0].shape\n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n        out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n        for frame in frames:\n            out.write(frame)\n        out.release()\n        \n    def putText(self, frame, text, top_left, bottom_right):\n        cv2.rectangle(frame, top_left, bottom_right, (0, 0, 0), thickness=cv2.FILLED)\n        cv2.putText(frame, text, (top_left[0] + 15, top_left[1] + 35), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n\n    def getVideo(self, videofile, outputfile):\n        cap = cv2.VideoCapture(videofile)\n        video_frames = []\n        \n        # The following x-coordinate describes the line, the intersection with which determines our vehicle count\n        xline = 500\n        # This set contains the ids of the tracked vehicles which intersected with our vertical line, vehicle_count should be the size of this set\n        intersectedIds = set()\n        \n        framect = 0\n        while True : \n            ret, frame = cap.read()\n            if not ret:\n                break\n            framect += 1\n        \n        print(f\"Processing {framect} frames\")\n        cap = cv2.VideoCapture(videofile)\n\n        for i in tqdm(range(framect)):\n            ret, frame = cap.read()\n            if not ret:\n                break\n                \n            detections = self.detector.getDetections(frame)\n            tracked_objects = self.tracker.getTrackedObjects(detections, frame)\n\n            video_frame = frame.copy()\n            linecolor = (252, 227, 3)\n            for obj in tracked_objects : \n                track_id = obj.track_id\n                bbox = obj.to_ltrb().astype(\"int\")\n                cv2.rectangle(video_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (int(track_id), 255, int(track_id)), 2)\n                cv2.putText(video_frame, str(track_id), (bbox[0], bbox[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n                \n                if bbox[0] <= xline and xline <= bbox[2]:\n                    if track_id not in intersectedIds:\n                        intersectedIds.add(track_id)\n                        linecolor = (255, 255, 255)\n                    \n            # Drawing the line and adding the count\n            h, w = video_frame.shape[:2]\n            cv2.line(video_frame, (xline, 0), (xline, h - 1), linecolor, 2)\n            self.putText(video_frame, f'Count: {len(intersectedIds)}', (w - 200, 50), (w - 45, 100))\n            \n            video_frames.append(video_frame)\n\n        cap.release()\n        self.writeVideo(video_frames, output_file = outputfile)\n\nvehicleTracker = VehicleTracker(detectorFasterRCNN, trackerDeepSORT)         ","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:57:57.187728Z","iopub.execute_input":"2024-03-16T07:57:57.188120Z","iopub.status.idle":"2024-03-16T07:57:57.205971Z","shell.execute_reply.started":"2024-03-16T07:57:57.188088Z","shell.execute_reply":"2024-03-16T07:57:57.205035Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"vehicleTracker.getVideo('/kaggle/input/intersectiondata01/vid2.mp4', \"output1.mp4\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:58:00.929510Z","iopub.execute_input":"2024-03-16T07:58:00.930546Z","iopub.status.idle":"2024-03-16T08:04:36.250089Z","shell.execute_reply.started":"2024-03-16T07:58:00.930506Z","shell.execute_reply":"2024-03-16T08:04:36.249074Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Processing 1775 frames\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1775/1775 [06:11<00:00,  4.77it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}