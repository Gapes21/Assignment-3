{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309a0e3c",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e13ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "cifar10Train = torchvision.datasets.CIFAR10(\"./CIFAR10\", download=True, transform=lambda im: torchvision.transforms.functional.pil_to_tensor(im)/255)\n",
    "cifar10Test = torchvision.datasets.CIFAR10(\"./CIFAR10\", train=False, download=True, transform=lambda im: torchvision.transforms.functional.pil_to_tensor(im)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2377056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import PIL\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad470287",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87a94d",
   "metadata": {},
   "source": [
    "## CNN1\n",
    "\n",
    "3 Conv, 2 FC, No dropout, no batch norm\n",
    "\n",
    "Activation fn: ReLU\n",
    "\n",
    "Optimizer: SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51879f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(3, 16, (3, 3), padding='same').to(device)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d((2, 2), stride=(2, 2)).to(device)\n",
    "\n",
    "        self.cnn2 = nn.Conv2d(16, 32, (3, 3), padding='same').to(device)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d((2, 2), stride=(2,2)).to(device)\n",
    "\n",
    "        self.cnn3 = nn.Conv2d(32, 64, (3, 3), padding='same').to(device)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d((2, 2), stride=(2,2)).to(device)\n",
    "\n",
    "        self.linear1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.linear2 = nn.Linear(512, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.linear3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.cnn1(inputs)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.cnn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.cnn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu5(x)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c620321",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(cifar10Train, 64)\n",
    "testloader = DataLoader(cifar10Test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dfa3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = CNN1().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(cnn1.parameters(), 1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6b32c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimzer, loss_fn, training_loader):\n",
    "    running_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        \n",
    "    average_loss = running_loss/(i+1)\n",
    "\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f28d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tdataset, model):\n",
    "    preds = []\n",
    "    truths = []\n",
    "    for example in tdataset:\n",
    "        input = example[0].unsqueeze(0).to(device)\n",
    "        logits = model(input)\n",
    "        pred = torch.argmax(torch.softmax(logits, 1))\n",
    "        preds.append(pred.item())\n",
    "        truths.append(example[1])\n",
    "    return accuracy_score(truths, preds), f1_score(truths, preds, average='macro'), preds, truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c247829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "\n",
    "def load_model(model, filepath, device='cpu'):\n",
    "    model.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b66be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train loss: 2.301 | train accuracy: 12.61% | train f1: 0.05 | test loss: 2.301 | test accuracy: 12.77% | test f1: 0.05 | time: 97.47s\n",
      "Epoch 20 | train loss: 2.296 | train accuracy: 17.74% | train f1: 0.10 | test loss: 2.295 | test accuracy: 17.43% | test f1: 0.10 | time: 247.46s\n",
      "Epoch 30 | train loss: 2.216 | train accuracy: 18.65% | train f1: 0.11 | test loss: 2.201 | test accuracy: 19.06% | test f1: 0.11 | time: 397.67s\n",
      "Epoch 40 | train loss: 1.983 | train accuracy: 28.25% | train f1: 0.25 | test loss: 1.969 | test accuracy: 28.95% | test f1: 0.26 | time: 548.40s\n",
      "Epoch 50 | train loss: 1.842 | train accuracy: 33.87% | train f1: 0.32 | test loss: 1.832 | test accuracy: 34.33% | test f1: 0.32 | time: 698.74s\n",
      "Epoch 60 | train loss: 1.655 | train accuracy: 37.26% | train f1: 0.35 | test loss: 1.732 | test accuracy: 37.19% | test f1: 0.35 | time: 849.32s\n",
      "Epoch 70 | train loss: 1.535 | train accuracy: 37.02% | train f1: 0.36 | test loss: 1.744 | test accuracy: 37.06% | test f1: 0.35 | time: 999.37s\n",
      "Epoch 80 | train loss: 1.451 | train accuracy: 42.22% | train f1: 0.41 | test loss: 1.599 | test accuracy: 42.55% | test f1: 0.41 | time: 1149.57s\n",
      "Epoch 90 | train loss: 1.387 | train accuracy: 45.98% | train f1: 0.45 | test loss: 1.508 | test accuracy: 45.69% | test f1: 0.44 | time: 1299.76s\n",
      "Epoch 100 | train loss: 1.330 | train accuracy: 48.96% | train f1: 0.48 | test loss: 1.437 | test accuracy: 48.14% | test f1: 0.47 | time: 1450.29s\n",
      "Epoch 110 | train loss: 1.276 | train accuracy: 51.30% | train f1: 0.50 | test loss: 1.382 | test accuracy: 50.57% | test f1: 0.49 | time: 1599.01s\n",
      "Epoch 120 | train loss: 1.224 | train accuracy: 53.42% | train f1: 0.52 | test loss: 1.342 | test accuracy: 52.18% | test f1: 0.51 | time: 1748.33s\n",
      "Epoch 130 | train loss: 1.172 | train accuracy: 55.33% | train f1: 0.54 | test loss: 1.305 | test accuracy: 53.87% | test f1: 0.52 | time: 1898.86s\n",
      "Epoch 140 | train loss: 1.121 | train accuracy: 57.65% | train f1: 0.57 | test loss: 1.262 | test accuracy: 55.61% | test f1: 0.54 | time: 2048.12s\n",
      "Epoch 150 | train loss: 1.072 | train accuracy: 59.67% | train f1: 0.59 | test loss: 1.231 | test accuracy: 56.87% | test f1: 0.56 | time: 2194.75s\n",
      "Epoch 160 | train loss: 1.023 | train accuracy: 61.68% | train f1: 0.61 | test loss: 1.203 | test accuracy: 58.19% | test f1: 0.57 | time: 2341.33s\n",
      "Epoch 170 | train loss: 0.976 | train accuracy: 63.48% | train f1: 0.63 | test loss: 1.186 | test accuracy: 59.15% | test f1: 0.59 | time: 2491.02s\n",
      "Epoch 180 | train loss: 0.929 | train accuracy: 65.35% | train f1: 0.65 | test loss: 1.166 | test accuracy: 60.03% | test f1: 0.60 | time: 2640.97s\n",
      "Epoch 190 | train loss: 0.883 | train accuracy: 66.77% | train f1: 0.67 | test loss: 1.159 | test accuracy: 60.35% | test f1: 0.60 | time: 2788.88s\n",
      "Epoch 200 | train loss: 0.837 | train accuracy: 67.89% | train f1: 0.68 | test loss: 1.161 | test accuracy: 60.37% | test f1: 0.60 | time: 2939.68s\n",
      "Epoch 210 | train loss: 0.791 | train accuracy: 69.14% | train f1: 0.69 | test loss: 1.166 | test accuracy: 60.74% | test f1: 0.61 | time: 3090.42s\n",
      "Epoch 220 | train loss: 0.743 | train accuracy: 69.98% | train f1: 0.70 | test loss: 1.185 | test accuracy: 60.45% | test f1: 0.61 | time: 3238.93s\n",
      "Epoch 230 | train loss: 0.695 | train accuracy: 70.87% | train f1: 0.71 | test loss: 1.211 | test accuracy: 60.32% | test f1: 0.61 | time: 3388.29s\n",
      "Epoch 240 | train loss: 0.646 | train accuracy: 72.62% | train f1: 0.73 | test loss: 1.223 | test accuracy: 60.63% | test f1: 0.61 | time: 3537.06s\n",
      "Epoch 250 | train loss: 0.596 | train accuracy: 74.72% | train f1: 0.75 | test loss: 1.233 | test accuracy: 61.59% | test f1: 0.62 | time: 3685.67s\n",
      "Epoch 260 | train loss: 0.545 | train accuracy: 77.02% | train f1: 0.77 | test loss: 1.247 | test accuracy: 62.08% | test f1: 0.62 | time: 3836.27s\n",
      "Epoch 270 | train loss: 0.492 | train accuracy: 79.14% | train f1: 0.79 | test loss: 1.283 | test accuracy: 62.39% | test f1: 0.63 | time: 3986.80s\n",
      "Epoch 280 | train loss: 0.438 | train accuracy: 80.88% | train f1: 0.81 | test loss: 1.341 | test accuracy: 62.34% | test f1: 0.63 | time: 4135.51s\n",
      "Epoch 290 | train loss: 0.384 | train accuracy: 82.13% | train f1: 0.82 | test loss: 1.421 | test accuracy: 62.15% | test f1: 0.62 | time: 4286.18s\n",
      "Epoch 300 | train loss: 0.336 | train accuracy: 84.40% | train f1: 0.85 | test loss: 1.485 | test accuracy: 62.59% | test f1: 0.63 | time: 4436.67s\n",
      "Epoch 310 | train loss: 0.280 | train accuracy: 85.95% | train f1: 0.86 | test loss: 1.583 | test accuracy: 62.65% | test f1: 0.63 | time: 4587.55s\n",
      "Epoch 320 | train loss: 0.250 | train accuracy: 86.89% | train f1: 0.87 | test loss: 1.695 | test accuracy: 62.66% | test f1: 0.63 | time: 4737.57s\n",
      "Epoch 330 | train loss: 0.195 | train accuracy: 87.27% | train f1: 0.87 | test loss: 1.848 | test accuracy: 62.10% | test f1: 0.63 | time: 4887.97s\n",
      "Epoch 340 | train loss: 0.162 | train accuracy: 88.32% | train f1: 0.89 | test loss: 1.957 | test accuracy: 62.31% | test f1: 0.63 | time: 5038.37s\n",
      "Epoch 350 | train loss: 0.207 | train accuracy: 90.64% | train f1: 0.91 | test loss: 2.015 | test accuracy: 63.07% | test f1: 0.63 | time: 5189.00s\n",
      "Epoch 360 | train loss: 0.072 | train accuracy: 92.08% | train f1: 0.92 | test loss: 2.220 | test accuracy: 63.03% | test f1: 0.63 | time: 5339.39s\n",
      "Epoch 370 | train loss: 0.110 | train accuracy: 93.22% | train f1: 0.93 | test loss: 2.232 | test accuracy: 63.38% | test f1: 0.64 | time: 5489.72s\n",
      "Epoch 380 | train loss: 0.039 | train accuracy: 95.04% | train f1: 0.95 | test loss: 2.431 | test accuracy: 63.42% | test f1: 0.64 | time: 5640.26s\n",
      "Epoch 390 | train loss: 0.027 | train accuracy: 96.17% | train f1: 0.96 | test loss: 2.602 | test accuracy: 63.27% | test f1: 0.63 | time: 5789.44s\n",
      "Epoch 400 | train loss: 0.020 | train accuracy: 96.92% | train f1: 0.97 | test loss: 2.749 | test accuracy: 63.21% | test f1: 0.63 | time: 5939.67s\n",
      "Epoch 410 | train loss: 0.015 | train accuracy: 97.60% | train f1: 0.98 | test loss: 2.878 | test accuracy: 63.23% | test f1: 0.63 | time: 6089.54s\n",
      "Epoch 420 | train loss: 0.012 | train accuracy: 98.14% | train f1: 0.98 | test loss: 2.985 | test accuracy: 63.24% | test f1: 0.63 | time: 6238.53s\n",
      "Epoch 430 | train loss: 0.010 | train accuracy: 98.54% | train f1: 0.99 | test loss: 3.082 | test accuracy: 63.44% | test f1: 0.64 | time: 6388.60s\n",
      "Epoch 440 | train loss: 0.008 | train accuracy: 98.85% | train f1: 0.99 | test loss: 3.165 | test accuracy: 63.37% | test f1: 0.64 | time: 6538.90s\n",
      "Epoch 450 | train loss: 0.007 | train accuracy: 99.16% | train f1: 0.99 | test loss: 3.239 | test accuracy: 63.47% | test f1: 0.64 | time: 6689.20s\n",
      "Epoch 460 | train loss: 0.006 | train accuracy: 99.34% | train f1: 0.99 | test loss: 3.307 | test accuracy: 63.64% | test f1: 0.64 | time: 6837.13s\n",
      "Epoch 470 | train loss: 0.005 | train accuracy: 99.49% | train f1: 0.99 | test loss: 3.371 | test accuracy: 63.59% | test f1: 0.64 | time: 6984.41s\n",
      "Epoch 480 | train loss: 0.004 | train accuracy: 99.60% | train f1: 1.00 | test loss: 3.430 | test accuracy: 63.65% | test f1: 0.64 | time: 7132.99s\n",
      "Epoch 490 | train loss: 0.004 | train accuracy: 99.69% | train f1: 1.00 | test loss: 3.484 | test accuracy: 63.73% | test f1: 0.64 | time: 7280.89s\n",
      "Epoch 500 | train loss: 0.003 | train accuracy: 99.76% | train f1: 1.00 | test loss: 3.534 | test accuracy: 63.76% | test f1: 0.64 | time: 7430.15s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "begin = time.time()\n",
    "\n",
    "max_f1 = -float('inf')\n",
    "\n",
    "log = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    cnn1.train(True)\n",
    "    average_train_loss = train_one_epoch(cnn1, optimizer, loss_fn, trainloader)\n",
    "\n",
    "    cnn1.eval()\n",
    "    running_test_loss = 0.\n",
    "    for i, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "        outputs = cnn1(inputs.to(device))\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "        running_test_loss += loss.item()\n",
    "    average_test_loss = running_test_loss/(i+1)\n",
    "    end = time.time()\n",
    "    log.append({'average_test_loss': average_test_loss, 'average_train_loss': average_train_loss, 'time_from_start': end-begin})\n",
    "    if (epoch+1)%10 == 0:\n",
    "        train_accuracy, train_f1, _, _ = evaluate(cifar10Train, cnn1)\n",
    "        test_accuracy, test_f1, _, _ = evaluate(cifar10Test, cnn1)\n",
    "        if test_f1 > max_f1:\n",
    "            max_f1 = test_f1\n",
    "            save_model(cnn1, './models/cnn1.pth')\n",
    "        print(f\"Epoch {epoch+1} | train loss: {average_train_loss:.3f} | train accuracy: {100*train_accuracy:.2f}% | train f1: {train_f1:.2f} | test loss: {average_test_loss:.3f} | test accuracy: {100*test_accuracy:.2f}% | test f1: {test_f1:.2f} | time: {end-begin:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f018d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
